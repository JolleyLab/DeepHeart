{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import monai\n",
    "\n",
    "from monai.engines import SupervisedEvaluator, SupervisedTrainer\n",
    "from monai.metrics.metric import IterationMetric\n",
    "from monai.metrics.utils import do_metric_reduction\n",
    "\n",
    "# from ignite.metrics.epoch_metric import EpochMetric\n",
    "from monai.handlers import (\n",
    "    ValidationHandler,\n",
    "    CheckpointSaver,\n",
    "    LrScheduleHandler,\n",
    "    MeanDice,\n",
    "    StatsHandler,\n",
    "    TensorBoardImageHandler,\n",
    "    TensorBoardStatsHandler,\n",
    "    GarbageCollector,\n",
    "    EarlyStopHandler\n",
    ")\n",
    "\n",
    "from monai.inferers import SimpleInferer\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandAffined,\n",
    "    ToTensord,\n",
    "    RandAdjustContrastd,\n",
    "    ScaleIntensityd,\n",
    "    RandScaleIntensityd,\n",
    "    ScaleIntensityRangePercentilesd,\n",
    "    AsDiscreted, \n",
    "    KeepLargestConnectedComponentd\n",
    ")\n",
    "\n",
    "from monai.engines.utils import CommonKeys as Keys\n",
    "from monai.data import DataLoader\n",
    "from monai.engines.utils import IterationEvents\n",
    "\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.engine import Events\n",
    "\n",
    "# Local imports\n",
    "from utils import generate_directory_name, get_list_of_file_names\n",
    "from loss import DicePlusConstantCatCrossEntropyLoss\n",
    "from optimizer import RAdam\n",
    "from transforms import DistanceTransformd, OneHotTransformd\n",
    "from model import VNet\n",
    "from metric import LossMetric\n",
    "\n",
    "# monai.config.print_config()\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch(batch, device, non_blocking=False):\n",
    "    input_fields = [\"mid-systolic-images\", \"annuli\"]\n",
    "    inputs = [batch[input_field].to(device) for input_field in input_fields]\n",
    "    inputs = torch.cat(inputs, dim=1)\n",
    "    batch[Keys.IMAGE] = inputs\n",
    "    batch[Keys.LABEL] = batch[\"labels\"].to(device)\n",
    "    return batch[Keys.IMAGE], batch[Keys.LABEL]\n",
    "\n",
    "\n",
    "def prepare_device(n_gpu_use: int):\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    if n_gpu_use > 0 and n_gpu == 0:\n",
    "        print(\"Warning: There\\'s no GPU available on this machine, training will be performed on CPU.\")\n",
    "        n_gpu_use = 0\n",
    "    if n_gpu_use > n_gpu:\n",
    "        print(\"Warning: The number of GPU\\'s configured to use is {}, but only {} are available on this \"\n",
    "                   \"machine.\".format(n_gpu_use, n_gpu))\n",
    "        n_gpu_use = n_gpu\n",
    "    device = torch.device('cuda:0' if n_gpu_use > 0 else 'cpu')\n",
    "    list_ids = list(range(n_gpu_use))\n",
    "    return device, list_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaflet_names = [\"anterior\", \"posterior\", \"septal\"]\n",
    "name = \"single_phase_with_annulus\"\n",
    "\n",
    "\n",
    "data_dir = \"/data/in/DL_DATA_224_224_224_6_vox_min_tricuspid/train\"\n",
    "\n",
    "output_dir = \"/data/out/test_monai\"\n",
    "directory = generate_directory_name()\n",
    "checkpoint_dir = Path(output_dir) / name / directory\n",
    "train_log_dir = Path(output_dir) / name / directory / \"training\"\n",
    "val_log_dir = Path(output_dir) / name / directory / \"validation\"\n",
    "\n",
    "\n",
    "validation_split = 0.1\n",
    "n_gpu = 2\n",
    "batch_size = 8\n",
    "num_workers = 8\n",
    "use_amp = True\n",
    "max_epochs = 200\n",
    "\n",
    "all_keys = [\"mid-systolic-images\", \"annuli\", \"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_rad = 30 * np.pi/180\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=all_keys, reader=\"NibabelReader\"),\n",
    "        AddChanneld(keys=all_keys),\n",
    "        RandAffined(\n",
    "            keys=all_keys, \n",
    "            prob=0.5, \n",
    "            rotate_range=(-rot_rad,rot_rad), # radians! \n",
    "            translate_range=(-30,30),\n",
    "            scale_range=(-0.2,0.2), \n",
    "            mode=\"nearest\", \n",
    "            padding_mode=\"zeros\", \n",
    "            as_tensor_output=False\n",
    "        ),\n",
    "        OneHotTransformd(keys=[\"labels\"]),\n",
    "        DistanceTransformd(keys=[\"annuli\"]),\n",
    "        RandScaleIntensityd(\n",
    "            keys=[\"mid-systolic-images\"],\n",
    "            factors=0.3,\n",
    "            prob=0.5\n",
    "        ),\n",
    "        ScaleIntensityd(\n",
    "            keys=[\"mid-systolic-images\"], \n",
    "            minv=0.0,\n",
    "            maxv=1.0\n",
    "        ),\n",
    "        ToTensord(keys=all_keys)\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=all_keys, reader=\"NibabelReader\"),\n",
    "        AddChanneld(keys=all_keys),\n",
    "        OneHotTransformd(keys=[\"labels\"]),\n",
    "        DistanceTransformd(keys=[\"annuli\"]),\n",
    "#         ScaleIntensityRangePercentilesd(\n",
    "#             keys=[\"mid-systolic-images\"], \n",
    "#             lower=2, \n",
    "#             upper=99, \n",
    "#             b_min=0.0, \n",
    "#             b_max=1.0, \n",
    "#             clip=True, \n",
    "#             relative=True\n",
    "#         ),\n",
    "        ScaleIntensityd(\n",
    "            keys=[\"mid-systolic-images\"], \n",
    "            minv=0.0,\n",
    "            maxv=1.0\n",
    "        ),\n",
    "        ToTensord(keys=all_keys)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "post_transforms = Compose(\n",
    "    [\n",
    "        AsDiscreted(keys=Keys.PRED, threshold_values=True),\n",
    "        KeepLargestConnectedComponentd(keys=Keys.PRED, applied_labels=[1,2,3]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader (train / validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from glob import glob\n",
    "\n",
    "n_samples = len(get_list_of_file_names(os.path.join(data_dir, \"mid-systolic-images\")))\n",
    "\n",
    "len_valid = int(n_samples * validation_split)\n",
    "\n",
    "# get all files for all directories\n",
    "images = sorted(get_list_of_file_names(os.path.join(data_dir, \"mid-systolic-images\"), absolute_path=True))\n",
    "annuli = sorted(get_list_of_file_names(os.path.join(data_dir, \"annuli\"), absolute_path=True))\n",
    "labels = sorted(get_list_of_file_names(os.path.join(data_dir, \"labels\"), absolute_path=True))\n",
    "\n",
    "\n",
    "train_files = [{\"mid-systolic-images\":  img, \"annuli\": ann, \"labels\": lbl} for img, ann, lbl in zip(images[:n_samples-len_valid],\n",
    "                                                                                                   annuli[:n_samples-len_valid],\n",
    "                                                                                                   labels[:n_samples-len_valid])]\n",
    "\n",
    "val_files = [{\"mid-systolic-images\": img, \"annuli\": ann, \"labels\": lbl} for img, ann, lbl in zip(images[n_samples-len_valid:],\n",
    "                                                                                                   annuli[n_samples-len_valid:],\n",
    "                                                                                                   labels[n_samples-len_valid:])]\n",
    "train_dataset = monai.data.Dataset(train_files, transform=train_transforms)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "val_dataset = monai.data.Dataset(val_files, transform=val_transforms)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "print(\"Num training datasets:\", len(train_files))\n",
    "print(\"Num validation datasets:\", len(val_files))\n",
    "\n",
    "print(\"first dataset:\")\n",
    "import pprint\n",
    "pprint.pprint(train_files[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network, Loss, Optimizer, LR Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device, device_ids = prepare_device(n_gpu_use=n_gpu)\n",
    "\n",
    "# Custom VNet\n",
    "net = VNet(\n",
    "    n_channels=2,\n",
    "    n_classes=4,\n",
    "    n_filters=16,\n",
    "    normalization=\"batchnorm\"\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# from monai.networks.nets.vnet import VNet\n",
    "\n",
    "# # NET\n",
    "# net = VNet(\n",
    "#     in_channels=2,\n",
    "#     out_channels=4,\n",
    "#     act=\"relu\"\n",
    "# ).to(device)\n",
    "\n",
    "\n",
    "# Multi-GPU Training\n",
    "if len(device_ids) > 1:\n",
    "    net = torch.nn.DataParallel(net, device_ids=device_ids).cuda()\n",
    "    \n",
    "# LOSS\n",
    "loss_function = DicePlusConstantCatCrossEntropyLoss(\n",
    "    boundaries_weight_factor=50,\n",
    "    boundaries_pool=3,\n",
    "    sigma=0.02\n",
    ")\n",
    "\n",
    "trainable_params = filter(lambda p: p.requires_grad, net.parameters())\n",
    "\n",
    "# OPTIMIZER\n",
    "# NB: as of now using local copy of RAdam optimizer but seems to be integrated into pytorch soon (https://github.com/pytorch/pytorch/pull/58968)\n",
    "optimizer = RAdam(\n",
    "    params=trainable_params, \n",
    "    lr=0.02, \n",
    "    weight_decay=1e-05\n",
    ")\n",
    "\n",
    "# SCHEDULER\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    optimizer=optimizer,\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) Restore previous model state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_file = \"/home/herzc/sources/DeepHeartPrivate/notebooks/Visualization/mid_systolic_images_with_annulus_detached.pth\"\n",
    "# checkpoint = torch.load(checkpoint_file)\n",
    "# net.load_state_dict(checkpoint['state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedValidator(SupervisedEvaluator):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.loss_function = kwargs.pop(\"loss_function\")\n",
    "        super(SupervisedValidator, self).__init__(**kwargs)\n",
    "        \n",
    "    def _iteration(self, engine, batchdata):\n",
    "        if batchdata is None:\n",
    "            raise ValueError(\"Must provide batch data for current iteration.\")\n",
    "        batch = self.prepare_batch(batchdata, engine.state.device, engine.non_blocking)\n",
    "        if len(batch) == 2:\n",
    "            inputs, targets = batch\n",
    "            args: Tuple = ()\n",
    "            kwargs: Dict = {}\n",
    "        else:\n",
    "            inputs, targets, args, kwargs = batch\n",
    "\n",
    "        # put iteration outputs into engine.state\n",
    "        engine.state.output = {Keys.IMAGE: inputs, Keys.LABEL: targets}\n",
    "        # execute forward computation\n",
    "        with self.mode(self.network):\n",
    "            if self.amp:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    predictions = self.inferer(inputs, self.network, *args, **kwargs)\n",
    "                    loss = self.loss_function(predictions, targets).mean()\n",
    "            else:\n",
    "                predictions = self.inferer(inputs, self.network, *args, **kwargs)\n",
    "                loss = self.loss_function(predictions, targets).mean()\n",
    "                \n",
    "        engine.state.output[Keys.PRED] = predictions\n",
    "        engine.state.output[\"val_loss\"] = loss.item()\n",
    "        engine.fire_event(IterationEvents.FORWARD_COMPLETED)\n",
    "        engine.fire_event(IterationEvents.MODEL_COMPLETED)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return engine.state.output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_handlers = [\n",
    "    ProgressBar(),\n",
    "    GarbageCollector(\"epoch\")\n",
    "]\n",
    "\n",
    "\n",
    "validator = SupervisedEvaluator(\n",
    "    device=device,\n",
    "    val_data_loader=val_data_loader,\n",
    "    prepare_batch=prepare_batch,\n",
    "    network=net,\n",
    "    inferer=SimpleInferer(),\n",
    "    key_val_metric={\n",
    "        \"val_mean_dice\": MeanDice(include_background=False, output_transform=lambda x: (x[Keys.PRED], x[Keys.LABEL]))\n",
    "    },\n",
    "    additional_metrics={\n",
    "        \"val_loss\": LossMetric(metric_fn=loss_function, output_transform=lambda x: (x[Keys.PRED], x[Keys.LABEL])),\n",
    "#         \"val_mean_dice_anterior\": MeanDice(include_background=False, output_transform=lambda x: (x[Keys.PRED][:,1,:], x[Keys.LABEL][:,1,:])),\n",
    "#         \"val_mean_dice_posterior\": MeanDice(include_background=False, output_transform=lambda x: (x[Keys.PRED][:,2,:], x[Keys.LABEL][:,2,:])),\n",
    "#         \"val_mean_dice_septal\": MeanDice(include_background=False, output_transform=lambda x: (x[Keys.PRED][:,3,:], x[Keys.LABEL][:,3,:]))\n",
    "    },\n",
    "    val_handlers=val_handlers,\n",
    "    post_transform=post_transforms,\n",
    "    amp=use_amp\n",
    ")\n",
    "\n",
    "    \n",
    "train_handlers = [\n",
    "    ValidationHandler(\n",
    "        validator=validator, \n",
    "        interval=1, \n",
    "        epoch_level=True\n",
    "    ),\n",
    "    StatsHandler(\n",
    "        tag_name=\"train_loss\", \n",
    "        output_transform=lambda x: x[Keys.LOSS]\n",
    "    ),\n",
    "    CheckpointSaver(\n",
    "        save_dir=checkpoint_dir, \n",
    "        save_dict={\"net\": net, \"opt\": optimizer}, \n",
    "        save_interval=5, \n",
    "        epoch_level=True\n",
    "    ),\n",
    "    GarbageCollector(\"epoch\")\n",
    "]\n",
    "\n",
    "\n",
    "trainer = SupervisedTrainer(\n",
    "    device=device,\n",
    "    max_epochs=max_epochs,\n",
    "    train_data_loader=train_data_loader,\n",
    "    prepare_batch=prepare_batch,\n",
    "    network=net,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    inferer=SimpleInferer(),\n",
    "    key_train_metric={\n",
    "        \"train_mean_dice\": MeanDice(include_background=False, output_transform=lambda x: (x[Keys.PRED], x[Keys.LABEL])),\n",
    "    },\n",
    "    additional_metrics={\n",
    "#         \"train_mean_dice_anterior\": MeanDice(include_background=False, output_transform=lambda x: (x[Keys.PRED][:,1,:], x[Keys.LABEL][:,1,:])),\n",
    "#         \"train_mean_dice_posterior\": MeanDice(include_background=False, output_transform=lambda x: (x[Keys.PRED][:,2,:], x[Keys.LABEL][:,2,:])),\n",
    "#         \"train_mean_dice_septal\": MeanDice(include_background=False, output_transform=lambda x: (x[Keys.PRED][:,3,:], x[Keys.LABEL][:,3,:]))\n",
    "    },\n",
    "    train_handlers=train_handlers,\n",
    "    post_transform=post_transforms,\n",
    "    amp=use_amp\n",
    ")\n",
    "\n",
    "\n",
    "# more handlers\n",
    "StatsHandler(\n",
    "    output_transform=lambda x: None,\n",
    "    global_epoch_transform=lambda x: trainer.state.epoch\n",
    ").attach(validator)\n",
    "\n",
    "\n",
    "LrScheduleHandler(\n",
    "    lr_scheduler=lr_scheduler, \n",
    "    print_lr=True, \n",
    "    step_transform=lambda x: x.state.metrics[\"val_loss\"]\n",
    ").attach(validator)\n",
    "\n",
    "\n",
    "TensorBoardStatsHandler(\n",
    "    log_dir=val_log_dir,\n",
    "    output_transform=lambda x: None,\n",
    "    global_epoch_transform=lambda x: trainer.state.epoch\n",
    ").attach(validator)\n",
    "\n",
    "\n",
    "# add handler to draw the first image and the corresponding label and model output in the last batch\n",
    "# here we draw the 3D output as GIF format along Depth axis, at every validation epoch\n",
    "val_tensorboard_image_handler = TensorBoardImageHandler(\n",
    "    log_dir=val_log_dir,\n",
    "    batch_transform=lambda x: (x[Keys.IMAGE], x[Keys.LABEL]),\n",
    "    output_transform=lambda x: x[Keys.PRED],\n",
    "    max_channels=10,\n",
    "    global_iter_transform=lambda x: trainer.state.epoch,\n",
    ")\n",
    "validator.add_event_handler(\n",
    "    event_name=Events.EPOCH_COMPLETED, handler=val_tensorboard_image_handler\n",
    ")\n",
    "\n",
    "TensorBoardStatsHandler(\n",
    "    log_dir=train_log_dir, \n",
    "    tag_name=\"train_loss\", \n",
    "    output_transform=lambda x: x[Keys.LOSS],\n",
    "    global_epoch_transform=lambda x: trainer.state.iteration\n",
    ").attach(trainer)\n",
    "\n",
    "\n",
    "EarlyStopHandler(\n",
    "    patience=30,\n",
    "    score_function=lambda x: x.state.metrics[\"val_mean_dice\"],\n",
    "    trainer=trainer,\n",
    "    epoch_level=True,\n",
    ").attach(validator)\n",
    "\n",
    "\n",
    "@trainer.on(IterationEvents.FORWARD_COMPLETED)\n",
    "def run_post_transform(engine):\n",
    "    pred = engine.state.output[Keys.PRED]\n",
    "    engine.state.output[Keys.PRED] = torch.nn.functional.softmax(pred.reshape(pred.size(0), pred.size(1), -1), dim=1).view_as(pred)\n",
    "\n",
    "    \n",
    "@validator.on(IterationEvents.FORWARD_COMPLETED)\n",
    "def run_post_transform(engine):\n",
    "    pred = engine.state.output[Keys.PRED]\n",
    "    engine.state.output[Keys.PRED] = torch.nn.functional.softmax(pred.reshape(pred.size(0), pred.size(1), -1), dim=1).view_as(pred)\n",
    "\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: asynchronous post transform call. has absolutely no effect on loss function inputs\n",
    "# from monai.transforms import apply_transform\n",
    "# \n",
    "# post_transforms = Compose(\n",
    "#     [\n",
    "#         Activationsd(keys=Keys.PRED,\n",
    "#                      other=lambda x: torch.nn.functional.softmax(x.reshape(x.size(0), x.size(1), -1), dim=1).view_as(x)),\n",
    "# #         AsDiscreted(keys=[\"pred\", \"label\"], argmax=(True, False), to_onehot=True, n_classes=4)\n",
    "#         AsDiscreted(keys=[Keys.LABEL], to_onehot=True, n_classes=4)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# from monai.engines.utils import IterationEvents\n",
    "# from monai.transforms import apply_transform\n",
    "\n",
    "# @trainer.on(IterationEvents.FORWARD_COMPLETED)\n",
    "# def run_post_transform(engine):\n",
    "#     print(\"running post transforms\")\n",
    "#     print(engine.state.output.keys())\n",
    "#     engine.state.output = apply_transform(post_transforms, engine.state.output)\n",
    "#     print(engine.state.output[\"label\"].shape)\n",
    "#     print(\"completed\")\n",
    "\n",
    "# val_loss = \"val_loss\"\n",
    "\n",
    "# @validator.on(IterationEvents.FORWARD_COMPLETED)\n",
    "# def run_post_transform(engine):\n",
    "#     engine.state.output[Keys.LOSS] = loss_function(engine.state.output[Keys.PRED], engine.state.output[Keys.LABEL])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# paths = [\n",
    "#     os.path.join(os.getcwd(), \"..\", \"..\")\n",
    "# ]\n",
    "\n",
    "# for path in paths:\n",
    "#     if not path in sys.path:\n",
    "#         sys.path.insert(0, path)\n",
    "\n",
    "# from deeputils.display import showImage\n",
    "\n",
    "# from monai.utils.misc import first\n",
    "# from pathlib import Path\n",
    "\n",
    "# data_dict = first(train_data_loader)\n",
    "\n",
    "# for idx, data_dict in enumerate(train_data_loader):\n",
    "#     # print(data_dict[\"mid-systolic-images\"].shape, data_dict[\"anterior\"].shape, data_dict[\"image_meta_dict\"][\"filename_or_obj\"])\n",
    "# #     print(f\"unique labels: {np.unique(data_dict['labels'])}\")\n",
    "# #     print(data_dict['mid-systolic-images_meta_dict']['filename_or_obj'])\n",
    "\n",
    "#     showImage(data_dict[\"mid-systolic-images\"], n_disp_images=5)\n",
    "#     showImage(data_dict[\"labels\"], n_disp_images=5)\n",
    "#     showImage(data_dict[\"labels\"][:,0,:], n_disp_images=5, case_name=Path(data_dict['mid-systolic-images_meta_dict']['filename_or_obj'][0]).name)\n",
    "#     showImage(data_dict[\"annuli\"], n_disp_images=5, case_name=Path(data_dict['mid-systolic-images_meta_dict']['filename_or_obj'][0]).name)\n",
    "\n",
    "#     if idx == 7:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai",
   "language": "python",
   "name": "monai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
